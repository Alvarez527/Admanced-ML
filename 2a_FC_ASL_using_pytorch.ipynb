{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#  Carlos Álvarez\n",
    "\n",
    "### **Git-hub: https://github.com/Alvarez527**\n",
    "### **Linkedin: www.linkedin.com/in/cralvarez-ai**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Objective\n",
    "\n",
    "    The primary aim of this activity is to transition from using Numpy for network implementation to utilizing PyTorch, a powerful deep learning framework. You will be replicating the work you did for the ASL dataset in Activity 1b, but this time, you'll implement a your multi layer FC model using PyTorch.\n",
    "    \n",
    "- Instructions\n",
    "\n",
    "    Review Previous Work: Begin by reviewing your Numpy-based Fully Connected Network for the ASL dataset from Activity 1b. Note the architecture, hyperparameters, and performance metrics for comparison.\n",
    "\n",
    "    Introduce PyTorch: If you're new to PyTorch, take some time to familiarize yourself with its basic operations and syntax. You can consult the official documentation or follow online tutorials.\n",
    "\n",
    "    Prepare the ASL Dataset: As before, download and preprocess the Kaggle ASL dataset. \n",
    "\n",
    "    Implement the Network: Design your network architecture tailored for the ASL dataset. Pay special attention to PyTorch modules like nn.Linear() and nn.ReLU().\n",
    "\n",
    "    Train the Model: Implement the training loop, making use of PyTorch's autograd to handle backpropagation. Monitor metrics like loss and accuracy as the model trains.\n",
    "\n",
    "    Analyze and Document: In Markdown cells, discuss the architecture choices, any differences in performance between the Numpy and PyTorch implementations, and insights gained from using a deep learning framework like PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar imágenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_images import get_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST path\n",
    "mnist_path = './archive'\n",
    "x_train_num, y_train_num, x_test_num, y_test_num = get_images(mnist_path)\n",
    "\n",
    "x_train = x_train_num[:50000].reshape(50000, -1).astype(np.float64)\n",
    "y_train = y_train_num[:50000].reshape(50000, 1)\n",
    "\n",
    "x_val = x_train_num[50000:].reshape(10000, -1).astype(np.float64)\n",
    "y_val = y_train_num[50000:].reshape(10000, 1)\n",
    "\n",
    "x_test = x_test_num.copy().reshape(10000, -1).astype(np.float64)\n",
    "y_test = y_test_num.copy().reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizar imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9.646705203355238e-18, 0.9999999999999997)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostrar imágenes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La imagen muestreada representa un: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {y_test[rnd_idx, 0]}')\n",
    "plot_number(x_test_num[rnd_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear minibatches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(x, y, mb_size, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]  \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora sí! PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convertir Numpy array a PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train.copy())\n",
    "y_train_tensor = torch.tensor(y_train.copy())\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val.copy())\n",
    "y_val_tensor = torch.tensor(y_val.copy())\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test.copy())\n",
    "y_test_tensor = torch.tensor(y_test.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Usar GPU de estar disponible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estammos usando: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'Estammos usando: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y, mb_size):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    model.eval() #Particularidad de pytorch para evaluar el modelo, no se requiere calcular gradientes\n",
    "    model = model.to(device=device) #se indica donde se quiere correr el modelo\n",
    "    with torch.no_grad(): #se pide no calcular gradientes\n",
    "        for (xi, yi) in create_minibatches(x, y, mb_size):\n",
    "            xi = xi.to(device=device, dtype = torch.float32) #se cargan los modelos a la memoria de gpu o cpu\n",
    "            yi = yi.to(device=device, dtype = torch.long) #se cargan los modelos a la memoria de gpu o cpu\n",
    "            scores = model(xi) # mb_size, 10\n",
    "            _, pred = scores.max(dim=1) #pred shape (mb_size ), de el indice del numero mayor a lo largo de las columnas\n",
    "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
    "            num_total += pred.size(0)\n",
    "\n",
    "            return float(num_correct)/num_total     \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, mb_size, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(epochs):\n",
    "        for (xi, yi) in create_minibatches(x_train_tensor, y_train_tensor, mb_size):\n",
    "            model.train() #Se pide que el modelo se encuentre en modo entrenamiento\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "            # funcion cost\n",
    "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
    "            optimiser.zero_grad() #se ponen los gradientes en cero de la iteración anterior\n",
    "            cost.backward() #se calculan los gradientes\n",
    "            optimiser.step() #se actualizan los valores W y b\n",
    "            \n",
    "        print(f'Epoch: {epoch}, costo: {cost.item()}, accuracy: {accuracy(model, x_val_tensor, y_val_tensor, mb_size)}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo usando Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, costo: 1.9158837795257568, accuracy: 0.71826171875\n",
      "Epoch: 1, costo: 1.287726879119873, accuracy: 0.798828125\n",
      "Epoch: 2, costo: 0.8749881386756897, accuracy: 0.855224609375\n",
      "Epoch: 3, costo: 0.6630003452301025, accuracy: 0.8681640625\n",
      "Epoch: 4, costo: 0.566522479057312, accuracy: 0.8837890625\n",
      "Epoch: 5, costo: 0.5219600796699524, accuracy: 0.88427734375\n",
      "Epoch: 6, costo: 0.4339170753955841, accuracy: 0.89794921875\n",
      "Epoch: 7, costo: 0.42387667298316956, accuracy: 0.8955078125\n",
      "Epoch: 8, costo: 0.4075073003768921, accuracy: 0.903564453125\n",
      "Epoch: 9, costo: 0.38412296772003174, accuracy: 0.90576171875\n",
      "Epoch: 10, costo: 0.3311651349067688, accuracy: 0.904296875\n",
      "Epoch: 11, costo: 0.334409236907959, accuracy: 0.9111328125\n",
      "Epoch: 12, costo: 0.3114036023616791, accuracy: 0.910888671875\n",
      "Epoch: 13, costo: 0.3718222379684448, accuracy: 0.91357421875\n",
      "Epoch: 14, costo: 0.300380140542984, accuracy: 0.914306640625\n",
      "Epoch: 15, costo: 0.31382298469543457, accuracy: 0.91259765625\n",
      "Epoch: 16, costo: 0.261270135641098, accuracy: 0.91650390625\n",
      "Epoch: 17, costo: 0.3170757591724396, accuracy: 0.915283203125\n",
      "Epoch: 18, costo: 0.2985116243362427, accuracy: 0.918212890625\n",
      "Epoch: 19, costo: 0.285968542098999, accuracy: 0.923583984375\n",
      "Epoch: 20, costo: 0.2610362470149994, accuracy: 0.930419921875\n",
      "Epoch: 21, costo: 0.2999592125415802, accuracy: 0.9267578125\n",
      "Epoch: 22, costo: 0.29823341965675354, accuracy: 0.927001953125\n",
      "Epoch: 23, costo: 0.29147717356681824, accuracy: 0.9267578125\n",
      "Epoch: 24, costo: 0.2639113962650299, accuracy: 0.926513671875\n",
      "Epoch: 25, costo: 0.24093422293663025, accuracy: 0.932373046875\n",
      "Epoch: 26, costo: 0.22673703730106354, accuracy: 0.93212890625\n",
      "Epoch: 27, costo: 0.2513717710971832, accuracy: 0.93212890625\n",
      "Epoch: 28, costo: 0.2570468485355377, accuracy: 0.9345703125\n",
      "Epoch: 29, costo: 0.23890545964241028, accuracy: 0.929443359375\n",
      "Epoch: 30, costo: 0.219966858625412, accuracy: 0.939208984375\n",
      "Epoch: 31, costo: 0.25005701184272766, accuracy: 0.93896484375\n",
      "Epoch: 32, costo: 0.22206008434295654, accuracy: 0.942138671875\n",
      "Epoch: 33, costo: 0.2521727979183197, accuracy: 0.941162109375\n",
      "Epoch: 34, costo: 0.17630450427532196, accuracy: 0.93798828125\n",
      "Epoch: 35, costo: 0.22111451625823975, accuracy: 0.9375\n",
      "Epoch: 36, costo: 0.2022937685251236, accuracy: 0.944091796875\n",
      "Epoch: 37, costo: 0.21657204627990723, accuracy: 0.9453125\n",
      "Epoch: 38, costo: 0.23361310362815857, accuracy: 0.94384765625\n",
      "Epoch: 39, costo: 0.19261257350444794, accuracy: 0.943115234375\n",
      "Epoch: 40, costo: 0.1725819855928421, accuracy: 0.948974609375\n",
      "Epoch: 41, costo: 0.19391915202140808, accuracy: 0.943603515625\n",
      "Epoch: 42, costo: 0.17625366151332855, accuracy: 0.942138671875\n",
      "Epoch: 43, costo: 0.22058385610580444, accuracy: 0.946533203125\n",
      "Epoch: 44, costo: 0.1691443920135498, accuracy: 0.947265625\n",
      "Epoch: 45, costo: 0.2296225130558014, accuracy: 0.948486328125\n",
      "Epoch: 46, costo: 0.1854971945285797, accuracy: 0.948486328125\n",
      "Epoch: 47, costo: 0.1780976504087448, accuracy: 0.945556640625\n",
      "Epoch: 48, costo: 0.19698674976825714, accuracy: 0.947998046875\n",
      "Epoch: 49, costo: 0.21935586631298065, accuracy: 0.95068359375\n",
      "Epoch: 50, costo: 0.2055969089269638, accuracy: 0.951171875\n",
      "Epoch: 51, costo: 0.19048327207565308, accuracy: 0.948974609375\n",
      "Epoch: 52, costo: 0.1460566222667694, accuracy: 0.95556640625\n",
      "Epoch: 53, costo: 0.171152263879776, accuracy: 0.953857421875\n",
      "Epoch: 54, costo: 0.17359766364097595, accuracy: 0.955322265625\n",
      "Epoch: 55, costo: 0.1307544708251953, accuracy: 0.95654296875\n",
      "Epoch: 56, costo: 0.14365631341934204, accuracy: 0.953125\n",
      "Epoch: 57, costo: 0.17990076541900635, accuracy: 0.955810546875\n",
      "Epoch: 58, costo: 0.18727144598960876, accuracy: 0.95654296875\n",
      "Epoch: 59, costo: 0.17709867656230927, accuracy: 0.95654296875\n",
      "Epoch: 60, costo: 0.16016125679016113, accuracy: 0.95751953125\n",
      "Epoch: 61, costo: 0.15803243219852448, accuracy: 0.956787109375\n",
      "Epoch: 62, costo: 0.1381593942642212, accuracy: 0.95556640625\n",
      "Epoch: 63, costo: 0.15124444663524628, accuracy: 0.958984375\n",
      "Epoch: 64, costo: 0.16344965994358063, accuracy: 0.955322265625\n",
      "Epoch: 65, costo: 0.16599145531654358, accuracy: 0.955322265625\n",
      "Epoch: 66, costo: 0.1371535211801529, accuracy: 0.964599609375\n",
      "Epoch: 67, costo: 0.11783980578184128, accuracy: 0.95703125\n",
      "Epoch: 68, costo: 0.1430172175168991, accuracy: 0.955810546875\n",
      "Epoch: 69, costo: 0.1857209950685501, accuracy: 0.9638671875\n",
      "Epoch: 70, costo: 0.13439325988292694, accuracy: 0.96142578125\n",
      "Epoch: 71, costo: 0.17128886282444, accuracy: 0.95654296875\n",
      "Epoch: 72, costo: 0.14478126168251038, accuracy: 0.957275390625\n",
      "Epoch: 73, costo: 0.1655752956867218, accuracy: 0.9599609375\n",
      "Epoch: 74, costo: 0.13208968937397003, accuracy: 0.95654296875\n",
      "Epoch: 75, costo: 0.14051343500614166, accuracy: 0.96728515625\n",
      "Epoch: 76, costo: 0.11878962069749832, accuracy: 0.962890625\n",
      "Epoch: 77, costo: 0.13461950421333313, accuracy: 0.9599609375\n",
      "Epoch: 78, costo: 0.15705712139606476, accuracy: 0.96533203125\n",
      "Epoch: 79, costo: 0.12723581492900848, accuracy: 0.9599609375\n",
      "Epoch: 80, costo: 0.15598538517951965, accuracy: 0.959716796875\n",
      "Epoch: 81, costo: 0.1277618259191513, accuracy: 0.960205078125\n",
      "Epoch: 82, costo: 0.11292383819818497, accuracy: 0.963623046875\n",
      "Epoch: 83, costo: 0.11842773854732513, accuracy: 0.960693359375\n",
      "Epoch: 84, costo: 0.15902595221996307, accuracy: 0.966064453125\n",
      "Epoch: 85, costo: 0.15676382184028625, accuracy: 0.962890625\n",
      "Epoch: 86, costo: 0.1141531839966774, accuracy: 0.965087890625\n",
      "Epoch: 87, costo: 0.10692781209945679, accuracy: 0.962890625\n",
      "Epoch: 88, costo: 0.13673774898052216, accuracy: 0.962646484375\n",
      "Epoch: 89, costo: 0.12471722811460495, accuracy: 0.966064453125\n",
      "Epoch: 90, costo: 0.10564687103033066, accuracy: 0.967041015625\n",
      "Epoch: 91, costo: 0.13404034078121185, accuracy: 0.9609375\n",
      "Epoch: 92, costo: 0.1156417652964592, accuracy: 0.96337890625\n",
      "Epoch: 93, costo: 0.09902451932430267, accuracy: 0.968017578125\n",
      "Epoch: 94, costo: 0.10704366862773895, accuracy: 0.961669921875\n",
      "Epoch: 95, costo: 0.11454486846923828, accuracy: 0.965576171875\n",
      "Epoch: 96, costo: 0.10611933469772339, accuracy: 0.965576171875\n",
      "Epoch: 97, costo: 0.11556227505207062, accuracy: 0.962890625\n",
      "Epoch: 98, costo: 0.11135993897914886, accuracy: 0.965087890625\n",
      "Epoch: 99, costo: 0.10036853700876236, accuracy: 0.966796875\n"
     ]
    }
   ],
   "source": [
    "#Instanciar modelo\n",
    "hidden1 = 1000 \n",
    "hidden = 1000\n",
    "lr = 5e-2\n",
    "epochs = 100\n",
    "mb_size = 4096\n",
    "model1 = nn.Sequential(nn.Linear(in_features=784, out_features=hidden1), nn.ReLU(),\n",
    "                       nn.Linear(in_features=hidden1, out_features=hidden), nn.ReLU(),\n",
    "                       nn.Linear(in_features=hidden, out_features=10))\n",
    "optimiser = torch.optim.SGD(model1.parameters(), lr=lr)\n",
    "\n",
    "train(model1, optimiser, mb_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96435546875"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(model1, x_test_tensor,  y_test_tensor, mb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
